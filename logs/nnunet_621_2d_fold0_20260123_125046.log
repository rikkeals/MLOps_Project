2026-01-23 12:50:50.102 | INFO     | __main__:main:215 - Using seed: 42
2026-01-23 12:50:50.102 | INFO     | __main__:main:216 - Initializing nnU-Net training
2026-01-23 12:50:50.103 | INFO     | __main__:main:217 - Dataset=621, config=2d, fold=0, trainer=nnUNetTrainer_5epochs, device=cpu
2026-01-23 12:50:50.103 | INFO     | __main__:main:226 - nnU-Net environment variables set
2026-01-23 12:50:50.103 | DEBUG    | __main__:main:227 - nnUNet_raw=/home/mejse/dtu/MLOps_Project/data/nnUNet_raw
2026-01-23 12:50:50.104 | DEBUG    | __main__:main:228 - nnUNet_preprocessed=/home/mejse/dtu/MLOps_Project/data/nnUNet_preprocessed
2026-01-23 12:50:50.104 | DEBUG    | __main__:main:229 - nnUNet_results=/home/mejse/dtu/MLOps_Project/data/nnUNet_results
2026-01-23 12:50:50.104 | INFO     | __main__:main:249 - Starting nnU-Net training. Logs will be written to: /home/mejse/dtu/MLOps_Project/logs/nnunet_621_2d_fold0_20260123_125046.log
2026-01-23 12:50:50.104 | INFO     | __main__:main:250 - Executing command: nnUNetv2_train 621 2d 0 -tr nnUNetTrainer_5epochs -device cpu

========================================================================================================================
COMMAND: nnUNetv2_train 621 2d 0 -tr nnUNetTrainer_5epochs -device cpu
========================================================================================================================

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cpu

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2026-01-23 12:50:58.331502: do_dummy_2d_data_aug: False
2026-01-23 12:50:58.332490: Using splits from existing split file: /home/mejse/dtu/MLOps_Project/data/nnUNet_preprocessed/Dataset621_Hippocampus/splits_final.json
2026-01-23 12:50:58.333660: The split file contains 5 splits.
2026-01-23 12:50:58.334000: Desired fold for training: 0
2026-01-23 12:50:58.334104: This split has 208 training and 52 validation cases.

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset621_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 

2026-01-23 12:51:00.840710: Unable to plot network architecture:
2026-01-23 12:51:00.850369: No module named 'hiddenlayer'
2026-01-23 12:51:00.876009: 
2026-01-23 12:51:00.878768: Epoch 0
2026-01-23 12:51:00.879059: Current learning rate: 0.01
2026-01-23 13:18:33.006857: train_loss -0.0763
2026-01-23 13:18:33.013147: val_loss -0.4511
2026-01-23 13:18:33.013690: Pseudo dice [0.5463, 0.6398]
2026-01-23 13:18:33.014081: Epoch time: 1652.13 s
2026-01-23 13:18:33.014219: Yayy! New best EMA pseudo Dice: 0.593
2026-01-23 13:18:34.101128: 
2026-01-23 13:18:34.102086: Epoch 1
2026-01-23 13:18:34.102407: Current learning rate: 0.00818
2026-01-23 13:50:16.951703: train_loss -0.6531
2026-01-23 13:50:16.961069: val_loss -0.7575
2026-01-23 13:50:16.961488: Pseudo dice [0.8471, 0.825]
2026-01-23 13:50:16.962255: Epoch time: 1902.85 s
2026-01-23 13:50:16.962490: Yayy! New best EMA pseudo Dice: 0.6173
2026-01-23 13:50:18.953216: 
2026-01-23 13:50:18.954375: Epoch 2
2026-01-23 13:50:18.954653: Current learning rate: 0.00631
2026-01-23 14:14:49.865222: train_loss -0.7543
2026-01-23 14:14:49.872219: val_loss -0.7836
2026-01-23 14:14:49.872561: Pseudo dice [0.8613, 0.8433]
2026-01-23 14:14:49.873150: Epoch time: 1470.91 s
2026-01-23 14:14:49.873350: Yayy! New best EMA pseudo Dice: 0.6408
2026-01-23 14:14:50.953525: 
2026-01-23 14:14:50.960044: Epoch 3
2026-01-23 14:14:50.960271: Current learning rate: 0.00438
2026-01-23 14:52:21.265960: train_loss -0.7793
2026-01-23 14:52:21.278385: val_loss -0.7938
2026-01-23 14:52:21.278626: Pseudo dice [0.8686, 0.849]
2026-01-23 14:52:21.279104: Epoch time: 2250.31 s
2026-01-23 14:52:21.279226: Yayy! New best EMA pseudo Dice: 0.6626
2026-01-23 14:52:22.265606: 
2026-01-23 14:52:22.266481: Epoch 4
2026-01-23 14:52:22.266789: Current learning rate: 0.00235
2026-01-23 15:14:55.620439: train_loss -0.7906
2026-01-23 15:14:55.626073: val_loss -0.7977
2026-01-23 15:14:55.626300: Pseudo dice [0.8702, 0.8525]
2026-01-23 15:14:55.626836: Epoch time: 1353.36 s
2026-01-23 15:14:55.626974: Yayy! New best EMA pseudo Dice: 0.6825
2026-01-23 15:14:56.764617: Training done.
perform_everything_on_device=True is only supported for cuda devices! Setting this to False
2026-01-23 15:14:56.905017: Using splits from existing split file: /home/mejse/dtu/MLOps_Project/data/nnUNet_preprocessed/Dataset621_Hippocampus/splits_final.json
2026-01-23 15:14:56.909757: The split file contains 5 splits.
2026-01-23 15:14:56.910261: Desired fold for training: 0
2026-01-23 15:14:56.910528: This split has 208 training and 52 validation cases.
2026-01-23 15:14:56.912050: predicting hippocampus_017
2026-01-23 15:14:56.946628: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0
2026-01-23 15:15:14.233268: predicting hippocampus_019
2026-01-23 15:15:14.240065: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0
2026-01-23 15:15:23.598594: predicting hippocampus_033
2026-01-23 15:15:23.602228: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0
2026-01-23 15:15:32.865099: predicting hippocampus_035
2026-01-23 15:15:32.869006: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0
2026-01-23 15:15:40.991507: predicting hippocampus_037
2026-01-23 15:15:40.996349: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0
2026-01-23 15:15:48.231240: predicting hippocampus_049
2026-01-23 15:15:48.238288: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0
2026-01-23 15:15:56.319164: predicting hippocampus_052
2026-01-23 15:15:56.331068: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0
2026-01-23 15:16:05.982804: predicting hippocampus_065
2026-01-23 15:16:05.989581: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0
2026-01-23 15:16:13.415197: predicting hippocampus_083
2026-01-23 15:16:13.426722: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0
2026-01-23 15:16:21.552513: predicting hippocampus_088
2026-01-23 15:16:21.558268: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0
2026-01-23 15:16:29.166017: predicting hippocampus_090
2026-01-23 15:16:29.172029: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0
2026-01-23 15:16:37.848045: predicting hippocampus_092
2026-01-23 15:16:37.853528: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0
2026-01-23 15:16:42.877681: predicting hippocampus_095
2026-01-23 15:16:42.882875: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0
2026-01-23 15:16:51.320203: predicting hippocampus_107
2026-01-23 15:16:51.333850: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0
2026-01-23 15:16:58.738661: predicting hippocampus_108
2026-01-23 15:16:58.750043: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0
2026-01-23 15:17:06.794541: predicting hippocampus_123
2026-01-23 15:17:06.799684: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0
2026-01-23 15:17:13.928401: predicting hippocampus_125
2026-01-23 15:17:13.933632: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0
2026-01-23 15:17:30.790476: predicting hippocampus_157
2026-01-23 15:17:30.796046: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0
2026-01-23 15:17:38.573855: predicting hippocampus_164
2026-01-23 15:17:38.579950: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0
2026-01-23 15:17:58.730303: predicting hippocampus_169
2026-01-23 15:17:58.741375: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0
2026-01-23 15:18:07.781111: predicting hippocampus_175
2026-01-23 15:18:07.785403: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0
2026-01-23 15:18:15.094244: predicting hippocampus_185
2026-01-23 15:18:15.105736: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0
2026-01-23 15:18:22.879962: predicting hippocampus_190
2026-01-23 15:18:22.886774: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0
2026-01-23 15:18:30.375407: predicting hippocampus_194
2026-01-23 15:18:30.380810: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0
2026-01-23 15:18:37.770672: predicting hippocampus_204
2026-01-23 15:18:37.777084: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0
2026-01-23 15:18:46.197817: predicting hippocampus_205
2026-01-23 15:18:46.202963: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0
2026-01-23 15:18:53.480013: predicting hippocampus_210
2026-01-23 15:18:53.486050: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0
2026-01-23 15:19:03.150788: predicting hippocampus_217
2026-01-23 15:19:03.156080: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0
2026-01-23 15:19:09.559476: predicting hippocampus_219
2026-01-23 15:19:09.572115: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0
2026-01-23 15:19:17.563927: predicting hippocampus_229
2026-01-23 15:19:17.570398: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0
2026-01-23 15:19:25.331764: predicting hippocampus_244
2026-01-23 15:19:25.337152: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0
2026-01-23 15:19:32.390924: predicting hippocampus_261
2026-01-23 15:19:32.402361: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0
2026-01-23 15:19:46.564786: predicting hippocampus_264
2026-01-23 15:19:46.572454: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0
2026-01-23 15:19:55.659400: predicting hippocampus_277
2026-01-23 15:19:55.666498: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0
2026-01-23 15:20:09.682617: predicting hippocampus_280
2026-01-23 15:20:09.689406: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0
2026-01-23 15:20:15.854782: predicting hippocampus_286
2026-01-23 15:20:15.861377: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0
2026-01-23 15:20:26.309705: predicting hippocampus_288
2026-01-23 15:20:26.320946: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0
2026-01-23 15:20:35.854278: predicting hippocampus_289
2026-01-23 15:20:35.859382: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0
2026-01-23 15:20:43.773944: predicting hippocampus_296
2026-01-23 15:20:43.780401: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0
2026-01-23 15:20:50.903151: predicting hippocampus_305
2026-01-23 15:20:50.914463: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0
2026-01-23 15:20:57.950176: predicting hippocampus_308
2026-01-23 15:20:57.961441: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0
2026-01-23 15:21:06.759435: predicting hippocampus_317
2026-01-23 15:21:06.771797: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0
2026-01-23 15:21:14.193027: predicting hippocampus_327
2026-01-23 15:21:14.205232: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0
2026-01-23 15:21:19.462153: predicting hippocampus_330
2026-01-23 15:21:19.466489: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0
2026-01-23 15:21:27.267878: predicting hippocampus_332
2026-01-23 15:21:27.273485: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0
2026-01-23 15:21:34.864676: predicting hippocampus_338
2026-01-23 15:21:34.877779: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0
2026-01-23 15:21:44.824421: predicting hippocampus_349
2026-01-23 15:21:44.835650: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0
2026-01-23 15:21:51.555217: predicting hippocampus_350
2026-01-23 15:21:51.560422: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0
2026-01-23 15:21:59.408907: predicting hippocampus_356
2026-01-23 15:21:59.413870: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0
2026-01-23 15:22:07.616427: predicting hippocampus_358
2026-01-23 15:22:07.621998: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0
2026-01-23 15:22:15.313295: predicting hippocampus_374
2026-01-23 15:22:15.324179: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0
2026-01-23 15:22:23.288212: predicting hippocampus_394
2026-01-23 15:22:23.293510: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0
2026-01-23 15:22:37.502737: Validation complete
2026-01-23 15:22:37.502944: Mean Validation Dice:  0.8633481515548334
2026-01-23 15:22:44.678 | SUCCESS  | __main__:main:254 - Done! Training finished in 9114.6s
2026-01-23 15:22:44.690 | INFO     | __main__:main:255 - Log written to /home/mejse/dtu/MLOps_Project/logs/nnunet_621_2d_fold0_20260123_125046.log
2026-01-23 15:22:44.720 | ERROR    | __main__:main:278 - Training failed
Traceback (most recent call last):

  File "/home/mejse/dtu/MLOps_Project/src/mlops_project/train.py", line 292, in <module>
    main()
    └ <function main at 0x7a069bd46d40>

  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7a069c77ea20>
  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7a069c77eac0>
  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7a069c77e980>
  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7a069bbf1c60>
  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7a069c6beca0>
            └ <hydra._internal.hydra.Hydra object at 0x7a069cb81760>
  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7a069c77d940>
  File "/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'dataset': {'name': 'Dataset621_Hippocampus', 'dataset_id': 621, 'raw_root': 'data/original', 'nnunet_raw_root': 'data/nnUNe...
    │   │              └ <function main at 0x7a069bd46ca0>
    │   └ <property object at 0x7a069c736e30>
    └ JobReturn(overrides=[], cfg={'dataset': {'name': 'Dataset621_Hippocampus', 'dataset_id': 621, 'raw_root': 'data/original', 'n...

> File "/home/mejse/dtu/MLOps_Project/src/mlops_project/train.py", line 273, in main
    wandb.log(m, step=m["epoch"])
    │     │   │       └ {'train_loss': -0.7906, 'val_loss': -0.7977, 'pseudo_dice': 267.043625}
    │     │   └ {'train_loss': -0.7906, 'val_loss': -0.7977, 'pseudo_dice': 267.043625}
    │     └ <bound method Run.log of <wandb.sdk.wandb_run.Run object at 0x7a05b0dd2a20>>
    └ <module 'wandb' from '/home/mejse/miniconda3/envs/mlops_project/lib/python3.12/site-packages/wandb/__init__.py'>

KeyError: 'epoch'
