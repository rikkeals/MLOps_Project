2026-01-21 11:59:55.623 | INFO     | __main__:main:158 - Initializing nnU-Net training
2026-01-21 11:59:55.624 | INFO     | __main__:main:159 - Dataset=621, config=2d, fold=0, trainer=nnUNetTrainer_5epochs, device=cpu
2026-01-21 11:59:55.624 | INFO     | __main__:main:168 - nnU-Net environment variables set
2026-01-21 11:59:55.624 | DEBUG    | __main__:main:169 - nnUNet_raw=/home/mejse/dtu/MLOps_Project/data/nnUNet_raw
2026-01-21 11:59:55.624 | DEBUG    | __main__:main:170 - nnUNet_preprocessed=/home/mejse/dtu/MLOps_Project/data/nnUNet_preprocessed
2026-01-21 11:59:55.624 | DEBUG    | __main__:main:171 - nnUNet_results=/home/mejse/dtu/MLOps_Project/data/nnUNet_results
2026-01-21 11:59:55.624 | INFO     | __main__:main:191 - Starting nnU-Net training. Logs will be written to: /home/mejse/dtu/MLOps_Project/logs/nnunet_621_2d_fold0_20260121_115955.log
2026-01-21 11:59:55.624 | INFO     | __main__:main:192 - Executing command: nnUNetv2_train 621 2d 0 -tr nnUNetTrainer_5epochs -device cpu

========================================================================================================================
COMMAND: nnUNetv2_train 621 2d 0 -tr nnUNetTrainer_5epochs -device cpu
========================================================================================================================

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cpu

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2026-01-21 12:00:07.802731: do_dummy_2d_data_aug: False
2026-01-21 12:00:07.803726: Using splits from existing split file: /home/mejse/dtu/MLOps_Project/data/nnUNet_preprocessed/Dataset621_Hippocampus/splits_final.json
2026-01-21 12:00:07.804609: The split file contains 5 splits.
2026-01-21 12:00:07.804807: Desired fold for training: 0
2026-01-21 12:00:07.804952: This split has 208 training and 52 validation cases.

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset621_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 

2026-01-21 12:00:10.486904: Unable to plot network architecture:
2026-01-21 12:00:10.487100: No module named 'hiddenlayer'
2026-01-21 12:00:10.500990: 
2026-01-21 12:00:10.501241: Epoch 0
2026-01-21 12:00:10.501459: Current learning rate: 0.01
2026-01-21 14:54:58.731699: train_loss 0.0255
2026-01-21 14:54:58.738064: val_loss -0.2765
2026-01-21 14:54:58.738532: Pseudo dice [np.float32(0.5785), np.float32(0.2247)]
2026-01-21 14:54:58.739585: Epoch time: 10488.23 s
2026-01-21 14:54:58.739858: Yayy! New best EMA pseudo Dice: 0.4016000032424927
